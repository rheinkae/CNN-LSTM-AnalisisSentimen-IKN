{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb7fa59-b1f5-4fb7-b014-0aef4102625f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91f4e163-0187-4842-85ca-884ac6e32bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e696cb0-9706-46f1-962b-af9a4f2d979b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TopicClassifier:\n",
    "    topics = {\n",
    "        \"infrastruktur\": ['jalan', 'jembatan', 'bandara', 'pelabuhan', 'kereta api', 'transportasi', 'listrik', 'energi', 'telekomunikasi'],\n",
    "        \"ekonomi\": ['investasi', 'upah','perekonomian', 'hutang', 'utang', 'miskin','sengsara','pertumbuhan ekonomi', 'usaha', 'peluang bisnis', 'pajak', 'industri', 'perdagangan', 'pangan'],\n",
    "        \"lingkungan\": ['lingkungan', 'polusi','sumber daya alam', 'hutan', 'air', 'sampah', 'bencana alam', 'kebakaran hutan', 'penyelamatan lingkungan'],\n",
    "        \"pendidikan\": ['pendidikan', 'sekolah', 'guru', 'pembelajaran', 'penelitian', 'kampus', 'beasiswa', 'sistem pendidikan','bodoh'],\n",
    "        \"teknologi\": ['teknologi', 'digitalisasi', 'internet', 'sains', 'inovasi', 'robotika', 'kecerdasan buatan', 'blockchain', 'platform digital']\n",
    "    }\n",
    "\n",
    "    @staticmethod\n",
    "    def OneHotEncodingDataFrameClassifier(df, column_name):\n",
    "        for topic in TopicClassifier.topics.keys():\n",
    "            df[topic] = df[column_name].apply(lambda x: 1 if any(keyword in x for keyword in TopicClassifier.topics[topic]) else 0)\n",
    "        return df\n",
    "    \n",
    "    def TextClassifying(input_text):\n",
    "        topic_list = []\n",
    "        for topic, keywords in TopicClassifier.topics.items():\n",
    "            if any(keyword in input_text for keyword in keywords):\n",
    "                topic_list.append(topic)\n",
    "        return topic_list\n",
    "    \n",
    "    def CreateDictionaryPerTopic(dataframe, column):\n",
    "        topic_dict = {topic: [] for topic in TopicClassifier.topics}\n",
    "        for index, row in dataframe.iterrows():\n",
    "            for topic, keywords in TopicClassifier.topics.items():\n",
    "                if any(keyword in row[column] for keyword in keywords):\n",
    "                    topic_dict[topic].append(row[column])\n",
    "        return topic_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d568e5b-8328-4de9-bbbe-47f02b9ecb91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "  def OneHotEncodingDataFrameClassifier(cls, dataFrame, text_column:str):\n",
    "    '''\n",
    "    Akan mengembalikan df dengan kolom text serta one hot encoding dari topik-topik yang didefinisikan.\n",
    "    '''\n",
    "    # Copying Dataframe\n",
    "    df = dataFrame.copy()\n",
    "\n",
    "    # Initializing final Data\n",
    "    final_dict = {\n",
    "        'text' : []\n",
    "    }\n",
    "    for topic in cls.topics.keys():\n",
    "      final_dict[topic] = np.zeros(shape= (len(df),))\n",
    "    \n",
    "    print(\"Tahap 1\")\n",
    "    for i in tqdm(range(len(df))):\n",
    "      text = df.loc[i][text_column]\n",
    "      final_dict['text'].append(text)\n",
    "      classification = cls.__classify__(text)\n",
    "      for topic in classification:\n",
    "        final_dict[topic][i] = 1\n",
    "\n",
    "    final_df = pd.DataFrame(final_dict)\n",
    "    \n",
    "    # Deleting text with all zeros on topics\n",
    "    print(\"Tahap 2\")\n",
    "    for i in tqdm(range(len(final_df))):\n",
    "      jum = 0\n",
    "      for topic in cls.topics.keys():\n",
    "        jum += final_df.loc[i][topic]\n",
    "\n",
    "      if jum == 0:\n",
    "        final_df = final_df.drop(i)\n",
    "    \n",
    "    final_df = final_df.reset_index(drop=True)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "  @classmethod\n",
    "  def CreateDataFramePerTopic(cls, dataFrame, destinationPath, namaOutputFile, text_column):\n",
    "    '''\n",
    "    Akan membuat csv dari setiap topic yang sudah didefinisikan dan dari dataFrame yang dimasukkan, serta text berpacu kepada parameter (text_column)\n",
    "    '''\n",
    "    # Initialization\n",
    "    df = dataFrame.copy()\n",
    "    final_df_dict = {}\n",
    "    for topic in cls.topics.keys():\n",
    "      final_df_dict[topic] = pd.DataFrame(columns=df.columns)\n",
    "    if destinationPath[len(destinationPath)-1] != \"/\":\n",
    "      destinationPath += \"/\"\n",
    "    \n",
    "    # Classifying\n",
    "    for i in tqdm(range(len(df))):\n",
    "      text = df.loc[i][text_column]\n",
    "      classification = cls.__classify__(text)\n",
    "      for topic in classification:\n",
    "        final_df_dict[topic] = final_df_dict[topic].append(df.iloc[i],ignore_index = True)\n",
    "\n",
    "    # Output\n",
    "    for topic in list(final_df_dict.keys()):\n",
    "      final_df_dict[topic].to_csv(\"{}.csv\".format((destinationPath + namaOutputFile + \"_{}\".format(topic))), index=False)\n",
    "\n",
    "  @classmethod\n",
    "  def CreateDictionaryPerTopic(cls, dataFrame, text_column):\n",
    "    '''\n",
    "    Akan mereturn dictionary yang berisikan setiap topic yang sudah didefinisikan dan dari dataFrame yang dimasukkan, serta text berpacu kepada parameter (text_column)\n",
    "    '''\n",
    "    # Initialization\n",
    "    df = dataFrame.copy()\n",
    "    final_df_dict = {}\n",
    "    for topic in cls.topics.keys():\n",
    "      final_df_dict[topic] = pd.DataFrame(columns=df.columns)\n",
    "    \n",
    "    # Classifying\n",
    "    for i in tqdm(range(len(df))):\n",
    "      text = df.loc[i][text_column]\n",
    "      classification = cls.__classify__(text)\n",
    "      for topic in classification:\n",
    "        final_df_dict[topic] = final_df_dict[topic].append(df.iloc[i],ignore_index = True)\n",
    "\n",
    "    # Output\n",
    "    return final_df_dict\n",
    "\n",
    "\n",
    "  @classmethod\n",
    "  def TextClassifying(cls, text):\n",
    "    return cls.__classify__(text)\n",
    "\n",
    "  @classmethod\n",
    "  def __classify__(cls, text):\n",
    "    final_class = []\n",
    "    text_split = text.split(' ')\n",
    "    for i in range(len(text_split)):\n",
    "      kata = text_split[i]\n",
    "      for topic in cls.topics.keys():\n",
    "        if kata in cls.topics[topic]:\n",
    "          final_class.append(topic)\n",
    "    \n",
    "    return list(set(final_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c5033b7-f07e-4fdc-90fb-40c0d36b3cba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordcount.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "directory = 'C:\\\\Users\\\\user\\\\PENELITIAN SAINS DATA\\\\data\\\\predictV1'\n",
    "out_directory = 'C:\\\\Users\\\\user\\\\PENELITIAN SAINS DATA\\\\data\\\\classifiedV1'\n",
    "\n",
    "if not os.path.exists(out_directory):\n",
    "    os.mkdir(out_directory)\n",
    "    print(\"Directory Created at {}\".format(out_directory))\n",
    "\n",
    "files = os.listdir(directory)\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith('.csv'):\n",
    "        print(file)\n",
    "        df = pd.read_csv(os.path.join(directory, file))\n",
    "        \n",
    "        # Convert 'word' column to string type\n",
    "        df['word'] = df['word'].astype(str)\n",
    "        \n",
    "        df_temp = TopicClassifier.OneHotEncodingDataFrameClassifier(df, 'word')\n",
    "        df_temp.to_csv(os.path.join(out_directory, file), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8f887ef-aaa1-4cdb-b63b-25e9230dcd63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_dict = TopicClassifier.CreateDictionaryPerTopic(df, 'word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b5d280a-3759-425b-827a-c6896eefdbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ekonomi']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"rakyat miskin\"#@param {type:\"string\"}\n",
    "TopicClassifier.TextClassifying(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29842192-da80-4c99-82d9-4e15b5ca5b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
